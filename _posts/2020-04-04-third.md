# Kaggle Challenge: [Real or Not? NLP with Disaster Tweets](https://www.kaggle.com/c/nlp-getting-started)

## The problem

Twitter has become an important communication channel in times of emergency.
The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. 
Because of this, more agencies are interested in programatically monitoring Twitter (i.e. disaster relief organizations and news agencies).

But, it’s not always clear whether a person’s words are actually announcing a disaster. Take this example:

![](https://storage.googleapis.com/kaggle-media/competitions/tweet_screenshot.png)


The author explicitly uses the word “ABLAZE” but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it’s less clear to a machine.

In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a quick tutorial to get you up and running.

Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.

The challenge allows only **Auto ML** submissions, however in this post we're gonna use standard ML and AI techniques, witouth keeping into account AutoML

## Sentiment Classification

### Objective

Sentiment analysis is a common use case of NLP where the idea is to classify the tweet as positive, negative or neutral depending upon the text in the tweet.
So, in a ML setting, this can be tracted as a multi-class classification problem, where we have a Positive label (1), a Neutral label (0) and a Negative label (-1) for each sample (tweet).

Sentiment analysis allows businesses to identify customer sentiment toward products, brands or services in online conversations and feedback, so it can lead to useful insights in a production environment.
For example, an e-commerce customer can use sentiment analysis to automatically analyze 4,000+ reviews about their product, and discovered that customers were happy about their pricing but complained a lot about their customer service (like in the image below)
![](https://pcdn.piiojs.com/i/kqctmw/vw,671,vh,0,kc,1,r,1,pr,2,wp,1/https%3A%2F%2Fmonkeylearn.com%2Fstatic%2Fimg%2Fsentiment-analysis%2Fsentiment-analysis-example-new%402x.png)

### Types of Sentiment Analysis

In general, we can have several granularities of sentiment. For example, if polarity precision is important to your business, you might consider expanding your polarity categories to include:
- Very positive
- Positive
- Neutral
- Negative
- Very negative

In addition, in the litterature we can find several types of sentiment analysis:
#### Emotion detection
Emotion detection aims at detecting emotions, like happiness, frustration, anger, sadness, and so on.
Many emotion detection systems use lexicons (i.e. lists of words and the emotions they convey) or complex machine learning algorithms.
One of the downsides of using lexicons is that people express emotions in different ways. Some words that typically express anger, like bad or kill (e.g. your product is so bad or your customer support is killing me) might also express happiness (e.g. this is bad ass or you are killing it).

#### Aspect-based Sentiment Analysis
Usually, when analyzing sentiments of texts, let’s say product reviews, you’ll want to know which particular aspects or features people are mentioning in a positive, neutral, or negative way. That's where aspect-based sentiment analysis can help, for example in this text: "The battery life of this camera is too short", an aspect-based classifier would be able to determine that the sentence expresses a negative opinion about the feature battery life.

#### Multilingual sentiment analysis
Multilingual sentiment analysis can be difficult. It involves a lot of preprocessing and resources. Most of these resources are available online (e.g. sentiment lexicons), while others need to be created (e.g. translated corpora or noise detection algorithms), but you’ll need to know how to code to use them.

Alternatively, you could detect language in texts automatically, then train a custom sentiment analysis model to classify texts in the language of your choice.

### How does it work?
Sentiment analysis uses various Natural Language Processing (NLP) methods and algorithms.

The main types of algorithms used include:
- Rule-based systems: Perform sentiment analysis based on a set of manually crafted rules (e.g check "bad" words and "good" words frequencies).
- Automatic systems: Rely on machine learning techniques to learn from data. (e.g Tokenization with TFIDF + MLP classifier, Word-embeddings + log-reg, ensembles..)
- Hybrid systems: Combine both rule-based and automatic approaches.

### Evaluation
In order to evaluate a sentiment classification algorithm we can use several techniques.
For example we could use Accuracy, as showed in the below image:

![Accuracy Calculation](https://cdn-images-1.medium.com/max/800/1*5XuZ_86Rfce3qyLt7XMlhw.png)


However, since it could happen that negative and positive labels have a different distribution in the dataset, a more appropriate 
evaluation metric is the so called F1-Score. 
The F1 score is the armonic mean between precision and recall, so is calculated as shown in the below image:

![](https://i.stack.imgur.com/U0hjG.png)


## My Kaggle Approach!

In this challenge the sentiment is just classified as negative or positive (2-class classification problem) and here I'm gonna briefly describe the approach I used to reach an ~83% F1.
We'll start from EDA (Exploratory Data Analysis), then we show how I cleaned the data and, at the end, several models are shown and compared.

### Exploratory Data Analysis
In statistics, exploratory data analysis (EDA) is an approach to analyzing data sets to summarize their main characteristics, often with visual methods. 
A statistical model can be used or not, but primarily EDA is for seeing what the data can tell us beyond the formal modeling or hypothesis testing task.

For this challenge I've performed the following EDA:
- General dataset infos
  - Number of samples
  - Data Columns
  - Class Label Distributiom
- Text analysis
  - Number of characters in tweets
  - Number of words in a tweet
  - Average word lenght in a tweet
  - Word distribution
  - Hashtag Analysis
  - KW and Location Analysis

For the code, I suggest to take a look directly to my [Kaggle Notebook](https://www.kaggle.com/c/nlp-getting-started).

### Data Cleaning

As I explained in [previous post](https://marcomancini1994.github.io/2020/02/10/second.html), cleaning the data is a standard practice in NLP, since the datasets are mostly coming from real interactions.

The data cleaning pipeline I built for this challenge is composed by:
- stopwords removal
- URL removal
- HTML removal
- emoji removal
- punctuation removal

### Evaluating the models

#TODO


